"""
DOM XSS Trigger Strategies - Vulnerability Detector
Analysiert Taint-Flows und identifiziert XSS-Schwachstellen
"""
import re
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
import uuid

from foxhound.taint_flow import (
    TaintFlow, XSSVulnerability, TaintSource, TaintSink,
    SourceType, SinkType, Severity
)

logger = logging.getLogger(__name__)


@dataclass
class ExploitabilityAnalysis:
    """Ergebnis der Exploitability-Analyse"""
    is_exploitable: bool
    confidence: float
    reasons: List[str]
    suggested_payload: Optional[str] = None


class VulnerabilityDetector:
    """
    Analysiert Taint-Flows und identifiziert XSS-Schwachstellen.
    
    Funktionen:
    - Klassifizierung nach Severity
    - Exploitability-Analyse
    - Proof-of-Concept Generierung
    - Deduplizierung
    """
    
    # Severity-Matrix: (source_type, sink_type) -> base_severity
    SEVERITY_MATRIX = {
        # URL Sources
        (SourceType.URL, SinkType.HTML_INJECTION): Severity.CRITICAL,
        (SourceType.URL, SinkType.JS_EXECUTION): Severity.CRITICAL,
        (SourceType.URL, SinkType.URL_REDIRECT): Severity.HIGH,
        (SourceType.URL, SinkType.ATTRIBUTE): Severity.HIGH,
        
        # Storage Sources
        (SourceType.STORAGE, SinkType.HTML_INJECTION): Severity.HIGH,
        (SourceType.STORAGE, SinkType.JS_EXECUTION): Severity.HIGH,
        (SourceType.STORAGE, SinkType.URL_REDIRECT): Severity.MEDIUM,
        
        # DOM Sources
        (SourceType.DOM, SinkType.HTML_INJECTION): Severity.HIGH,
        (SourceType.DOM, SinkType.JS_EXECUTION): Severity.HIGH,
        (SourceType.DOM, SinkType.URL_REDIRECT): Severity.MEDIUM,
        
        # User Input Sources
        (SourceType.USER_INPUT, SinkType.HTML_INJECTION): Severity.MEDIUM,
        (SourceType.USER_INPUT, SinkType.JS_EXECUTION): Severity.HIGH,
        (SourceType.USER_INPUT, SinkType.URL_REDIRECT): Severity.MEDIUM,
    }
    
    # Sanitization-Patterns (reduzieren Exploitability)
    SANITIZATION_PATTERNS = [
        r'encodeURIComponent',
        r'escape\(',
        r'DOMPurify',
        r'sanitize',
        r'htmlEncode',
        r'escapeHtml',
        r'textContent\s*=',  # Sicherer als innerHTML
        r'createTextNode',
    ]
    
    # Gef√§hrliche Patterns (erh√∂hen Exploitability)
    DANGEROUS_PATTERNS = [
        r'innerHTML\s*[+]?=',
        r'outerHTML\s*[+]?=',
        r'document\.write',
        r'eval\s*\(',
        r'setTimeout\s*\([\'"]',
        r'setInterval\s*\([\'"]',
        r'new\s+Function\s*\(',
    ]
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.min_confidence = self.config.get('min_confidence', 0.3)
    
    def analyze(self, flows: List[TaintFlow]) -> List[XSSVulnerability]:
        """
        Analysiert Taint-Flows und identifiziert Vulnerabilities.
        
        Args:
            flows: Liste von TaintFlow Objekten
            
        Returns:
            Liste von XSSVulnerability Objekten
        """
        if not flows:
            return []
        
        vulnerabilities = []
        
        for flow in flows:
            vuln = self._analyze_flow(flow)
            if vuln and vuln.confidence >= self.min_confidence:
                vulnerabilities.append(vuln)
        
        # Deduplizierung
        unique_vulns = self._deduplicate(vulnerabilities)
        
        # Sortiere nach Severity
        unique_vulns.sort(key=lambda v: self._severity_order(v.severity), reverse=True)
        
        logger.info(f"üîç {len(flows)} Flows ‚Üí {len(unique_vulns)} Vulnerabilities")
        
        return unique_vulns
    
    def _analyze_flow(self, flow: TaintFlow) -> Optional[XSSVulnerability]:
        """Analysiert einen einzelnen Taint-Flow"""
        
        # Severity bestimmen
        severity = self._determine_severity(flow)
        
        # Exploitability analysieren
        exploitability = self._analyze_exploitability(flow)
        
        # Confidence berechnen
        confidence = self._calculate_confidence(flow, exploitability)
        
        # Update Flow
        flow.is_exploitable = exploitability.is_exploitable
        flow.severity = severity
        flow.confidence = confidence
        
        # Vulnerability erstellen
        vuln = XSSVulnerability(
            id=f"XSS-{uuid.uuid4().hex[:8]}",
            flows=[flow],
            severity=severity,
            category=self._determine_category(flow),
            source_summary=self._summarize_source(flow.source),
            sink_summary=self._summarize_sink(flow.sink),
            proof_of_concept=exploitability.suggested_payload,
            cwe_id="CWE-79",
            owasp_category="A03:2021-Injection",
            remediation=self._generate_remediation(flow),
            url=flow.url,
            confidence=confidence
        )
        
        return vuln
    
    def _determine_severity(self, flow: TaintFlow) -> Severity:
        """Bestimmt Severity basierend auf Source/Sink Kombination"""
        key = (flow.source.type, flow.sink.type)
        
        base_severity = self.SEVERITY_MATRIX.get(key, Severity.MEDIUM)
        
        # Anpassungen basierend auf Kontext
        # URL Hash ist besonders gef√§hrlich (reflected XSS)
        if 'hash' in flow.source.name.lower():
            if base_severity == Severity.HIGH:
                base_severity = Severity.CRITICAL
        
        # eval ist immer kritisch
        if 'eval' in flow.sink.name.lower():
            base_severity = Severity.CRITICAL
        
        return base_severity
    
    def _analyze_exploitability(self, flow: TaintFlow) -> ExploitabilityAnalysis:
        """Analysiert ob der Flow exploitable ist"""
        reasons = []
        confidence = 0.5  # Basis-Confidence
        
        # Pr√ºfe auf Sanitization in Propagation
        propagation_str = ' '.join([
            step.operation for step in flow.propagation
        ])
        
        has_sanitization = any(
            re.search(pattern, propagation_str, re.IGNORECASE)
            for pattern in self.SANITIZATION_PATTERNS
        )
        
        if has_sanitization:
            confidence -= 0.3
            reasons.append("M√∂gliche Sanitization erkannt")
        
        # Pr√ºfe auf gef√§hrliche Patterns
        has_dangerous = any(
            re.search(pattern, flow.sink.name, re.IGNORECASE)
            for pattern in self.DANGEROUS_PATTERNS
        )
        
        if has_dangerous:
            confidence += 0.2
            reasons.append("Gef√§hrlicher Sink erkannt")
        
        # URL-basierte Sources sind direkt erreichbar
        if flow.source.type == SourceType.URL:
            confidence += 0.15
            reasons.append("URL-basierte Source (direkt erreichbar)")
        
        # HTML Injection Sinks sind am gef√§hrlichsten
        if flow.sink.type == SinkType.HTML_INJECTION:
            confidence += 0.1
            reasons.append("HTML Injection Sink")
        
        # JS Execution ist kritisch
        if flow.sink.type == SinkType.JS_EXECUTION:
            confidence += 0.15
            reasons.append("JavaScript Execution Sink")
        
        # Begrenze auf [0, 1]
        confidence = max(0.0, min(1.0, confidence))
        
        # Payload generieren
        payload = self._generate_payload(flow)
        
        return ExploitabilityAnalysis(
            is_exploitable=confidence >= 0.5,
            confidence=confidence,
            reasons=reasons,
            suggested_payload=payload
        )
    
    def _generate_payload(self, flow: TaintFlow) -> str:
        """Generiert Proof-of-Concept Payload"""
        sink_type = flow.sink.type
        source_name = flow.source.name
        
        # Base Payloads nach Sink-Typ
        if sink_type == SinkType.HTML_INJECTION:
            payload = '<img src=x onerror=alert("XSS")>'
        elif sink_type == SinkType.JS_EXECUTION:
            payload = 'alert("XSS")'
        elif sink_type == SinkType.URL_REDIRECT:
            payload = 'javascript:alert("XSS")'
        else:
            payload = '"><script>alert("XSS")</script>'
        
        # Anpassung f√ºr Source
        if 'hash' in source_name:
            return f'#{payload}'
        elif 'search' in source_name:
            return f'?param={payload}'
        elif 'localStorage' in source_name or 'sessionStorage' in source_name:
            return f'localStorage.setItem("key", "{payload}")'
        
        return payload
    
    def _calculate_confidence(
        self, 
        flow: TaintFlow, 
        exploitability: ExploitabilityAnalysis
    ) -> float:
        """Berechnet finale Confidence"""
        base = exploitability.confidence
        
        # Bonus f√ºr kurze Propagation (weniger Chance auf Sanitization)
        if len(flow.propagation) <= 2:
            base += 0.1
        elif len(flow.propagation) >= 5:
            base -= 0.1
        
        # Begrenze auf [0, 1]
        return max(0.0, min(1.0, base))
    
    def _determine_category(self, flow: TaintFlow) -> str:
        """Bestimmt XSS-Kategorie"""
        if flow.source.type == SourceType.URL:
            if 'hash' in flow.source.name or 'search' in flow.source.name:
                return "DOM-based (Reflected)"
            return "DOM-based"
        elif flow.source.type == SourceType.STORAGE:
            return "DOM-based (Stored)"
        elif flow.source.type == SourceType.USER_INPUT:
            return "DOM-based (User Input)"
        else:
            return "DOM-based"
    
    def _summarize_source(self, source: TaintSource) -> str:
        """Erstellt lesbare Source-Zusammenfassung"""
        type_names = {
            SourceType.URL: "URL Parameter",
            SourceType.STORAGE: "Browser Storage",
            SourceType.DOM: "DOM Property",
            SourceType.USER_INPUT: "User Input",
            SourceType.API: "API Response"
        }
        
        type_name = type_names.get(source.type, "Unknown")
        return f"{type_name}: {source.name}"
    
    def _summarize_sink(self, sink: TaintSink) -> str:
        """Erstellt lesbare Sink-Zusammenfassung"""
        element = f" on {sink.element}" if sink.element else ""
        return f"{sink.name}{element}"
    
    def _generate_remediation(self, flow: TaintFlow) -> str:
        """Generiert Remediation-Empfehlung"""
        sink_type = flow.sink.type
        
        remediations = {
            SinkType.HTML_INJECTION: (
                "Verwende textContent statt innerHTML, oder sanitize den Input "
                "mit DOMPurify.sanitize() vor dem Einf√ºgen."
            ),
            SinkType.JS_EXECUTION: (
                "Vermeide eval(), new Function() und setTimeout/setInterval mit Strings. "
                "Verwende stattdessen sichere Alternativen wie JSON.parse() f√ºr Daten."
            ),
            SinkType.URL_REDIRECT: (
                "Validiere URLs gegen eine Whitelist erlaubter Domains. "
                "Verwende URL-Parser um das Protokoll zu pr√ºfen (kein javascript:)."
            ),
            SinkType.ATTRIBUTE: (
                "Verwende setAttribute() mit validierten Werten. "
                "F√ºr Event-Handler verwende addEventListener() statt Inline-Handler."
            )
        }
        
        return remediations.get(
            sink_type, 
            "Validiere und sanitize alle Benutzereingaben vor der Verwendung."
        )
    
    def _deduplicate(self, vulns: List[XSSVulnerability]) -> List[XSSVulnerability]:
        """Dedupliziert Vulnerabilities"""
        seen = set()
        unique = []
        
        for vuln in vulns:
            # Key basierend auf Source/Sink Kombination
            key = (vuln.source_summary, vuln.sink_summary)
            
            if key not in seen:
                seen.add(key)
                unique.append(vuln)
            else:
                # F√ºge Flow zu existierender Vulnerability hinzu
                for existing in unique:
                    if (existing.source_summary, existing.sink_summary) == key:
                        existing.flows.extend(vuln.flows)
                        # Update Confidence auf Maximum
                        existing.confidence = max(existing.confidence, vuln.confidence)
                        break
        
        return unique
    
    def _severity_order(self, severity: Severity) -> int:
        """Gibt Sortier-Ordnung f√ºr Severity"""
        order = {
            Severity.CRITICAL: 4,
            Severity.HIGH: 3,
            Severity.MEDIUM: 2,
            Severity.LOW: 1,
            Severity.INFO: 0
        }
        return order.get(severity, 0)
    
    def get_summary(self, vulns: List[XSSVulnerability]) -> Dict:
        """Erstellt Zusammenfassung der Vulnerabilities"""
        if not vulns:
            return {'total': 0}
        
        return {
            'total': len(vulns),
            'by_severity': {
                s.value: len([v for v in vulns if v.severity == s])
                for s in Severity
            },
            'by_category': {
                cat: len([v for v in vulns if v.category == cat])
                for cat in set(v.category for v in vulns)
            },
            'high_confidence': len([v for v in vulns if v.confidence >= 0.7]),
            'exploitable': len([v for v in vulns if any(f.is_exploitable for f in v.flows)])
        }
